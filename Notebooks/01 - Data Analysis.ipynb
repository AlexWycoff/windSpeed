{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "API_KEY = \"ZsmvG2hWSTkb2fwtjowaaPS5o8s5pbhft8IZSqrL\"\n",
    "EMAIL = \"biggerboi02@gmail.com\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T17:51:28.469141Z",
     "start_time": "2024-06-27T17:51:28.462840Z"
    }
   },
   "id": "8b8f7f9df88c9b83",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['244138',\n '30891',\n '56031',\n '58085',\n '282816',\n '118158',\n '88246',\n '178499',\n '326920',\n '164677',\n '146210',\n '73348',\n '80931',\n '68213',\n '261473',\n '335326',\n '190532',\n '336015',\n '15713',\n '239530',\n '128216',\n '85982',\n '171895',\n '16244',\n '128041',\n '366151',\n '264298',\n '64960',\n '107682',\n '324236',\n '8096',\n '34232',\n '139496',\n '55060',\n '254833',\n '144219',\n '64662',\n '335716',\n '172297',\n '307868',\n '134055',\n '216078',\n '151846',\n '233697',\n '231245',\n '184917',\n '335988',\n '13897',\n '171363',\n '311376',\n '235468',\n '103508',\n '26564',\n '212112',\n '161080',\n '43026',\n '200199',\n '216187',\n '187929',\n '61007',\n '8057',\n '137168',\n '89688',\n '25938',\n '49543',\n '169225',\n '368383',\n '98857',\n '191114',\n '13496',\n '298121',\n '325657',\n '133001',\n '51114',\n '221916',\n '167399',\n '11673',\n '199373',\n '41213',\n '7871',\n '108744',\n '34277',\n '339466',\n '292738',\n '136645',\n '303666',\n '104261',\n '124613',\n '67163',\n '238583',\n '166132',\n '23490',\n '371092',\n '274691',\n '232986',\n '236064',\n '126528',\n '102812',\n '19599',\n '316024']"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function used to generate the 100 random site ids: \n",
    "# np.random.randint(0, 388080, (100))\n",
    "\n",
    "site_ids = pd.read_csv(\"site ids\", index_col=0)\n",
    "site_ids = [str(site_ids.iloc[x, 0]) for x in range(100)]\n",
    "site_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T17:51:28.549233Z",
     "start_time": "2024-06-27T17:51:28.529883Z"
    }
   },
   "id": "e2829b48733d20c",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:05:10.464552Z",
     "start_time": "2024-06-27T18:05:09.055712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing name: 2000\n",
      "Making request for point group 1 of 1...\n",
      "Response data (you should replace this print statement with your processing):       Year  Month  Day  Hour  Minute  wind speed at 80m (m/s)  \\\n",
      "0     2000      1    1     0      30                    11.58   \n",
      "1     2000      1    1     1      30                     8.86   \n",
      "2     2000      1    1     2      30                     8.41   \n",
      "3     2000      1    1     3      30                     8.10   \n",
      "4     2000      1    1     4      30                     8.28   \n",
      "...    ...    ...  ...   ...     ...                      ...   \n",
      "8755  2000     12   31    19      30                    10.24   \n",
      "8756  2000     12   31    20      30                     9.78   \n",
      "8757  2000     12   31    21      30                    10.20   \n",
      "8758  2000     12   31    22      30                     8.25   \n",
      "8759  2000     12   31    23      30                     9.48   \n",
      "\n",
      "      wind direction at 80m (deg)  \n",
      "0                          269.18  \n",
      "1                          265.70  \n",
      "2                          264.26  \n",
      "3                          267.66  \n",
      "4                          236.51  \n",
      "...                           ...  \n",
      "8755                       348.61  \n",
      "8756                       351.99  \n",
      "8757                       344.38  \n",
      "8758                       358.24  \n",
      "8759                       352.42  \n",
      "\n",
      "[8760 rows x 7 columns]\n",
      "Processed\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://developer.nrel.gov/api/wind-toolkit/v2/wind/offshore-great-lakes-download.csv?\"\n",
    "POINTS = site_ids\n",
    "\n",
    "# Code provided by NREL to request and handle data\n",
    "# Some modifications have been made\n",
    "\n",
    "def main():\n",
    "    input_data = {\n",
    "        'attributes': 'windspeed_80m,winddirection_80m',\n",
    "        'interval': '60',\n",
    "\n",
    "        'api_key': API_KEY,\n",
    "        'email': EMAIL,\n",
    "    }\n",
    "    for name in ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
    "        print(f\"Processing name: {name}\")\n",
    "        for id, location_ids in enumerate(POINTS):\n",
    "            input_data['names'] = name\n",
    "            input_data['location_ids'] = location_ids\n",
    "            print(f'Making request for point group {id + 1} of {len(POINTS)}...')\n",
    "\n",
    "            if '.csv' in BASE_URL:\n",
    "                url = BASE_URL + urllib.parse.urlencode(input_data, True)\n",
    "                # Note: CSV format is only supported for single point requests\n",
    "                # Suggest that you might append to a larger data frame\n",
    "                data = pd.read_csv(url, on_bad_lines='skip', skiprows=2)\n",
    "                print(f'Response data for year {name} and site {location_ids}')\n",
    "                # You can use the following code to write it to a file\n",
    "                data.to_csv('SingleBigDataPoint.csv')\n",
    "            else:\n",
    "                headers = {\n",
    "                    'x-api-key': API_KEY\n",
    "                }\n",
    "                data = get_response_json_and_handle_errors(requests.post(BASE_URL, input_data, headers=headers))\n",
    "                download_url = data['outputs']['downloadUrl']\n",
    "                # You can do with what you will the download url\n",
    "                print(data['outputs']['message'])\n",
    "                print(f\"Data can be downloaded from this url when ready: {download_url}\")\n",
    "\n",
    "                data = pd.read_csv(download_url)\n",
    "\n",
    "                # Delay for 1 second to prevent rate limiting\n",
    "                time.sleep(1)\n",
    "            print(f'Processed')\n",
    "\n",
    "\n",
    "def get_response_json_and_handle_errors(response: requests.Response) -> dict:\n",
    "    \"\"\"Takes the given response and handles any errors, along with providing\n",
    "    the resulting json\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    response : requests.Response\n",
    "        The response object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The resulting json\n",
    "    \"\"\"\n",
    "    if response.status_code != 200:\n",
    "        print(f\"An error has occurred with the server or the request. The request response code/status: {response.status_code} {response.reason}\")\n",
    "        print(f\"The response body: {response.text}\")\n",
    "        exit(1)\n",
    "\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except:\n",
    "        print(f\"The response couldn't be parsed as JSON, likely an issue with the server, here is the text: {response.text}\")\n",
    "        exit(1)\n",
    "\n",
    "    if len(response_json['errors']) > 0:\n",
    "        errors = '\\n'.join(response_json['errors'])\n",
    "        print(f\"The request errored out, here are the errors: {errors}\")\n",
    "        exit(1)\n",
    "    return response_json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc009a22b501b69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
